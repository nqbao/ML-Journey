{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: protobuf==3.0.0 in /opt/conda/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: setuptools in /opt/conda/envs/python2/lib/python2.7/site-packages (from protobuf==3.0.0)\n",
      "Requirement already up-to-date: six>=1.9 in /opt/conda/envs/python2/lib/python2.7/site-packages (from protobuf==3.0.0)\n",
      "Requirement already up-to-date: appdirs>=1.4.0 in /opt/conda/envs/python2/lib/python2.7/site-packages (from setuptools->protobuf==3.0.0)\n",
      "Requirement already up-to-date: packaging>=16.8 in /opt/conda/envs/python2/lib/python2.7/site-packages (from setuptools->protobuf==3.0.0)\n",
      "Requirement already up-to-date: pyparsing in /opt/conda/envs/python2/lib/python2.7/site-packages (from packaging>=16.8->setuptools->protobuf==3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl\n",
    "!pip install --upgrade protobuf==3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘*.csv’: No such file or directory\n",
      "--2017-01-27 06:28:33--  https://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv\n",
      "Resolving vincentarelbundock.github.io (vincentarelbundock.github.io)... 151.101.52.133\n",
      "Connecting to vincentarelbundock.github.io (vincentarelbundock.github.io)|151.101.52.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4821 (4.7K) [text/csv]\n",
      "Saving to: ‘iris.csv’\n",
      "\n",
      "iris.csv            100%[=====================>]   4.71K  --.-KB/s   in 0s     \n",
      "\n",
      "2017-01-27 06:28:34 (62.2 MB/s) - ‘iris.csv’ saved [4821/4821]\n",
      "\n",
      "--2017-01-27 06:28:34--  http://download.tensorflow.org/data/iris_training.csv\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.3.176, 2607:f8b0:400a:806::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.3.176|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2194 (2.1K) [text/csv]\n",
      "Saving to: ‘iris_training.csv’\n",
      "\n",
      "iris_training.csv   100%[=====================>]   2.14K  --.-KB/s   in 0s     \n",
      "\n",
      "2017-01-27 06:28:34 (241 MB/s) - ‘iris_training.csv’ saved [2194/2194]\n",
      "\n",
      "--2017-01-27 06:28:34--  http://download.tensorflow.org/data/iris_test.csv\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 216.58.193.112, 2607:f8b0:400a:801::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|216.58.193.112|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 573 [text/csv]\n",
      "Saving to: ‘iris_test.csv’\n",
      "\n",
      "iris_test.csv       100%[=====================>]     573  --.-KB/s   in 0s     \n",
      "\n",
      "2017-01-27 06:28:35 (101 MB/s) - ‘iris_test.csv’ saved [573/573]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm *.csv\n",
    "!wget https://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv\n",
    "!wget http://download.tensorflow.org/data/iris_training.csv\n",
    "!wget http://download.tensorflow.org/data/iris_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "WARNING:tensorflow:Using default config.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Estimator(params={'enable_centered_bias': True, 'activation_fn': <function relu at 0x7f7cb18ba0c8>, 'weight_column_name': None, 'hidden_units': [10, 20, 10], 'feature_columns': [_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None)], 'n_classes': 3, 'optimizer': 'Adagrad', 'dropout': None, 'gradient_clip_norm': None, 'num_ps_replicas': 0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "\n",
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TRAINING,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)\n",
    "\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TEST,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"/tmp/iris_model\")\n",
    "classifier.fit(x=training_set.data,\n",
    "           y=training_set.target,\n",
    "           steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling _export_estimator (from tensorflow.contrib.learn.python.learn.utils.export) with default_batch_size=1 is deprecated and will be removed after 2016-09-23.\n",
      "Instructions for updating:\n",
      "The signature of the input_fn accepted by export is changing to be consistent with what's used by tf.Learn Estimator's train/evaluate. input_fn and input_feature_key will become required args. use_deprecated_input_fn will default to False and be removed. default_batch_size will also be removed since it will now be a part of the input_fn.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/iris_exported_model/00002000'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf /tmp/iris_exported*\n",
    "from tensorflow.contrib.learn.python.learn.utils import export\n",
    "from tensorflow.contrib.session_bundle import exporter\n",
    "\n",
    "def my_input_fn():\n",
    "    # Return features tensors\n",
    "    return {\n",
    "        \"\": tf.placeholder(tf.float32, shape=[None, 4])\n",
    "    }, None\n",
    "\n",
    "def my_signature_fn(examples,features,predictions):\n",
    "    return None,{\n",
    "        \"inputs\": exporter.generic_signature({\"features\": examples}),\n",
    "        \"outputs\": exporter.generic_signature({\"score\": predictions})\n",
    "    }\n",
    "\n",
    "classifier.export(\n",
    "    \"/tmp/iris_exported_model\",\n",
    "    input_fn=my_input_fn,\n",
    "    input_feature_key=\"\",\n",
    "    use_deprecated_input_fn=False,\n",
    "    signature_fn=my_signature_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XXX: this only works for tf 0.11\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import meta_graph_pb2\n",
    "from tensorflow.contrib.session_bundle import manifest_pb2\n",
    "\n",
    "def read_serving_signatures(meta_file):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        new_saver = tf.train.import_meta_graph(meta_file)\n",
    "\n",
    "        graph = tf.get_default_graph()\n",
    "        # print(graph.get_all_collection_keys())\n",
    "        pb = graph.get_collection(\"serving_signatures\")[0]\n",
    "        signatures = manifest_pb2.Signatures()\n",
    "        pb.Unpack(signatures)\n",
    "        \n",
    "        return signatures\n",
    "    \n",
    "def read_meta_graph(meta_file):\n",
    "    meta_graph = meta_graph_pb2.MetaGraphDef()\n",
    "    with open(meta_file, \"rb\") as f:\n",
    "        meta_graph.ParseFromString(f.read())\n",
    "        \n",
    "    return meta_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "named_signatures {\n",
       "  key: \"inputs\"\n",
       "  value {\n",
       "    generic_signature {\n",
       "      map {\n",
       "        key: \"features\"\n",
       "        value {\n",
       "          tensor_name: \"Placeholder:0\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "named_signatures {\n",
       "  key: \"outputs\"\n",
       "  value {\n",
       "    generic_signature {\n",
       "      map {\n",
       "        key: \"score\"\n",
       "        value {\n",
       "          tensor_name: \"Softmax:0\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist/00000001/export.meta\n",
    "# sales-forecast-model/export.meta\n",
    "# /tmp/iris_exported_model/00002000/export.meta\n",
    "\n",
    "signatures = read_serving_signatures('/tmp/iris_exported_model/00002000/export.meta')\n",
    "signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: ./iris.tar: file is the archive; not dumped\r\n"
     ]
    }
   ],
   "source": [
    "!(cd /tmp/iris_exported_model/00002000/ && tar -cf iris.tar . && mv iris.tar ~/work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
